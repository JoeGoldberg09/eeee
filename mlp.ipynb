{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUfV+Hu8nEzzZ46s2thVAx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoeGoldberg09/eeee/blob/main/mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP with N binary inputs, 2 hidden layers, 1 binary output (Random weights every step)"
      ],
      "metadata": {
        "id": "6XQXTcgXjWcH"
      }
    },
    {
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "N = 4\n",
        "hidden1 = 5\n",
        "hidden2 = 3\n",
        "output = 1\n",
        "\n",
        "X = np.random.randint(0, 2, (10, N))\n",
        "\n",
        "steps = 0\n",
        "while True:\n",
        "    steps += 1\n",
        "\n",
        "\n",
        "    W1 = np.random.randn(N, hidden1)\n",
        "    b1 = np.random.randn(hidden1)\n",
        "\n",
        "    W2 = np.random.randn(hidden1, hidden2)\n",
        "    b2 = np.random.randn(hidden2)\n",
        "\n",
        "    W3 = np.random.randn(hidden2, output)\n",
        "    b3 = np.random.randn(output)\n",
        "\n",
        "\n",
        "    h1 = np.dot(X, W1) + b1\n",
        "    h2 = np.dot(h1, W2) + b2\n",
        "    y_pred = np.dot(h2, W3) + b3\n",
        "\n",
        "\n",
        "    if steps >= 5:\n",
        "        break\n",
        "\n",
        "print(\"Final W1:\\n\", W1)\n",
        "print(\"Final b1:\\n\", b1)\n",
        "print(\"Final W2:\\n\", W2)\n",
        "print(\"Final b2:\\n\", b2)\n",
        "print(\"Final W3:\\n\", W3)\n",
        "print(\"Final b3:\\n\", b3)\n",
        "print(\"Steps:\", steps)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "QXZfmoG4NdQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # MLP with 4 binary inputs, 1 hidden layer, 2 binary outputs (Random weights every step)"
      ],
      "metadata": {
        "id": "Zg6sITI9jajz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "inputs = 4\n",
        "hidden = 5\n",
        "outputs = 2\n",
        "\n",
        "\n",
        "X = np.random.randint(0, 2, (10, inputs))\n",
        "\n",
        "steps = 0\n",
        "while True:\n",
        "    steps += 1\n",
        "\n",
        "\n",
        "    W1 = np.random.randn(inputs, hidden)\n",
        "    b1 = np.random.randn(hidden)\n",
        "\n",
        "    W2 = np.random.randn(hidden, outputs)\n",
        "    b2 = np.random.randn(outputs)\n",
        "\n",
        "\n",
        "    h1 = np.dot(X, W1) + b1\n",
        "    y_pred = np.dot(h1, W2) + b2\n",
        "\n",
        "    if steps >= 5:\n",
        "        break\n",
        "\n",
        "print(\"Final W1:\\n\", W1)\n",
        "print(\"Final b1:\\n\", b1)\n",
        "print(\"Final W2:\\n\", W2)\n",
        "print(\"Final b2:\\n\", b2)\n",
        "print(\"Steps:\", steps)\n"
      ],
      "metadata": {
        "id": "4DI2ueDgjbSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  MLP with N binary inputs, 2 hidden layers, 1 output — Backpropagation, Sigmoid Activation\n"
      ],
      "metadata": {
        "id": "5PQjbe_1jbse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def d_sigmoid(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "\n",
        "N = 4\n",
        "hidden1 = 5\n",
        "hidden2 = 3\n",
        "output = 1\n",
        "lr = 0.1\n",
        "\n",
        "\n",
        "X = np.random.randint(0, 2, (20, N))\n",
        "y = np.random.randint(0, 2, (20, 1))\n",
        "s\n",
        "W1 = np.random.randn(N, hidden1)\n",
        "b1 = np.zeros((1, hidden1))\n",
        "\n",
        "W2 = np.random.randn(hidden1, hidden2)\n",
        "b2 = np.zeros((1, hidden2))\n",
        "\n",
        "W3 = np.random.randn(hidden2, output)\n",
        "b3 = np.zeros((1, output))\n",
        "\n",
        "steps = 0\n",
        "for epoch in range(5000):\n",
        "    steps += 1\n",
        "\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    z3 = np.dot(a2, W3) + b3\n",
        "    y_pred = sigmoid(z3)\n",
        "\n",
        "\n",
        "    loss = np.mean((y - y_pred) ** 2)\n",
        "\n",
        "\n",
        "    d_loss = 2 * (y_pred - y) * d_sigmoid(z3)\n",
        "\n",
        "    dW3 = np.dot(a2.T, d_loss)\n",
        "    db3 = np.sum(d_loss, axis=0, keepdims=True)\n",
        "\n",
        "    d_hidden2 = np.dot(d_loss, W3.T) * d_sigmoid(z2)\n",
        "    dW2 = np.dot(a1.T, d_hidden2)\n",
        "    db2 = np.sum(d_hidden2, axis=0, keepdims=True)\n",
        "\n",
        "    d_hidden1 = np.dot(d_hidden2, W2.T) * d_sigmoid(z1)\n",
        "    dW1 = np.dot(X.T, d_hidden1)\n",
        "    db1 = np.sum(d_hidden1, axis=0, keepdims=True)\n",
        "\n",
        "\n",
        "    W3 -= lr * dW3\n",
        "    b3 -= lr * db3\n",
        "    W2 -= lr * dW2\n",
        "    b2 -= lr * db2\n",
        "    W1 -= lr * dW1\n",
        "    b1 -= lr * db1\n",
        "\n",
        "    if loss < 0.001:\n",
        "        break\n",
        "\n",
        "print(\"Final W1:\\n\", W1)\n",
        "print(\"Final b1:\\n\", b1)\n",
        "print(\"Final W2:\\n\", W2)\n",
        "print(\"Final b2:\\n\", b2)\n",
        "print(\"Final W3:\\n\", W3)\n",
        "print(\"Final b3:\\n\", b3)\n",
        "print(\"Steps:\", steps)\n"
      ],
      "metadata": {
        "id": "swbpkg8vjcFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP with N binary inputs, 2 hidden layers, 1 output — Backpropagation, ReLU Activation\n",
        "\n"
      ],
      "metadata": {
        "id": "4De_W9WHjcrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def d_relu(x):\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "\n",
        "N = 4\n",
        "hidden1 = 5\n",
        "hidden2 = 3\n",
        "output = 1\n",
        "lr = 0.01\n",
        "\n",
        "X = np.random.randint(0, 2, (20, N))\n",
        "y = np.random.randint(0, 2, (20, 1))\n",
        "\n",
        "W1 = np.random.randn(N, hidden1)\n",
        "b1 = np.zeros((1, hidden1))\n",
        "\n",
        "W2 = np.random.randn(hidden1, hidden2)\n",
        "b2 = np.zeros((1, hidden2))\n",
        "\n",
        "W3 = np.random.randn(hidden2, output)\n",
        "b3 = np.zeros((1, output))\n",
        "\n",
        "steps = 0\n",
        "for epoch in range(5000):\n",
        "    steps += 1\n",
        "\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = relu(z1)\n",
        "\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = relu(z2)\n",
        "\n",
        "    z3 = np.dot(a2, W3) + b3\n",
        "    y_pred = relu(z3)\n",
        "\n",
        "\n",
        "    loss = np.mean((y - y_pred) ** 2)\n",
        "\n",
        "\n",
        "    d_loss = 2 * (y_pred - y) * d_relu(z3)\n",
        "\n",
        "    dW3 = np.dot(a2.T, d_loss)\n",
        "    db3 = np.sum(d_loss, axis=0, keepdims=True)\n",
        "\n",
        "    d_hidden2 = np.dot(d_loss, W3.T) * d_relu(z2)\n",
        "    dW2 = np.dot(a1.T, d_hidden2)\n",
        "    db2 = np.sum(d_hidden2, axis=0, keepdims=True)\n",
        "\n",
        "    d_hidden1 = np.dot(d_hidden2, W2.T) * d_relu(z1)\n",
        "    dW1 = np.dot(X.T, d_hidden1)\n",
        "    db1 = np.sum(d_hidden1, axis=0, keepdims=True)\n",
        "\n",
        "\n",
        "    W3 -= lr * dW3\n",
        "    b3 -= lr * db3\n",
        "    W2 -= lr * dW2\n",
        "    b2 -= lr * db2\n",
        "    W1 -= lr * dW1\n",
        "    b1 -= lr * db1\n",
        "\n",
        "    if loss < 0.001:\n",
        "        break\n",
        "\n",
        "print(\"Final W1:\\n\", W1)\n",
        "print(\"Final b1:\\n\", b1)\n",
        "print(\"Final W2:\\n\", W2)\n",
        "print(\"Final b2:\\n\", b2)\n",
        "print(\"Final W3:\\n\", W3)\n",
        "print(\"Final b3:\\n\", b3)\n",
        "print(\"Steps:\", steps)\n"
      ],
      "metadata": {
        "id": "GbEk_8FUjdWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP with N binary inputs, 2 hidden layers, 1 output — Backpropagation, Tanh Activation"
      ],
      "metadata": {
        "id": "utLysWZgjdwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def d_tanh(x):\n",
        "    return 1 - np.tanh(x)**2\n",
        "\n",
        "N = 4\n",
        "hidden1 = 5\n",
        "hidden2 = 3\n",
        "output = 1\n",
        "lr = 0.01\n",
        "\n",
        "X = np.random.randint(0, 2, (20, N))\n",
        "y = np.random.randint(0, 2, (20, 1))\n",
        "\n",
        "W1 = np.random.randn(N, hidden1)\n",
        "b1 = np.zeros((1, hidden1))\n",
        "\n",
        "W2 = np.random.randn(hidden1, hidden2)\n",
        "b2 = np.zeros((1, hidden2))\n",
        "\n",
        "W3 = np.random.randn(hidden2, output)\n",
        "b3 = np.zeros((1, output))\n",
        "\n",
        "steps = 0\n",
        "for epoch in range(5000):\n",
        "    steps += 1\n",
        "\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = tanh(z1)\n",
        "\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = tanh(z2)\n",
        "\n",
        "    z3 = np.dot(a2, W3) + b3\n",
        "    y_pred = tanh(z3)\n",
        "\n",
        "\n",
        "    loss = np.mean((y - y_pred) ** 2)\n",
        "\n",
        "\n",
        "    d_loss = 2 * (y_pred - y) * d_tanh(z3)\n",
        "\n",
        "    dW3 = np.dot(a2.T, d_loss)\n",
        "    db3 = np.sum(d_loss, axis=0, keepdims=True)\n",
        "\n",
        "    d_hidden2 = np.dot(d_loss, W3.T) * d_tanh(z2)\n",
        "    dW2 = np.dot(a1.T, d_hidden2)\n",
        "    db2 = np.sum(d_hidden2, axis=0, keepdims=True)\n",
        "\n",
        "    d_hidden1 = np.dot(d_hidden2, W2.T) * d_tanh(z1)\n",
        "    dW1 = np.dot(X.T, d_hidden1)\n",
        "    db1 = np.sum(d_hidden1, axis=0, keepdims=True)\n",
        "\n",
        "\n",
        "    W3 -= lr * dW3\n",
        "    b3 -= lr * db3\n",
        "    W2 -= lr * dW2\n",
        "    b2 -= lr * db2\n",
        "    W1 -= lr * dW1\n",
        "    b1 -= lr * db1\n",
        "\n",
        "    if loss < 0.001:\n",
        "        break\n",
        "\n",
        "print(\"Final W1:\\n\", W1)\n",
        "print(\"Final b1:\\n\", b1)\n",
        "print(\"Final W2:\\n\", W2)\n",
        "print(\"Final b2:\\n\", b2)\n",
        "print(\"Final W3:\\n\", W3)\n",
        "print(\"Final b3:\\n\", b3)\n",
        "print(\"Steps:\", steps)\n"
      ],
      "metadata": {
        "id": "plTGlC7HjeSc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}